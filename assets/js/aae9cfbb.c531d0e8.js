"use strict";(self.webpackChunkclassic=self.webpackChunkclassic||[]).push([[9360],{1956:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"education/prompts/PRD/hallucination-detection","title":"Hallucination Detection","description":"Hallucination detection for the PRD","source":"@site/docs/education/02-prompts/01-PRD/27-hallucination-detection.mdx","sourceDirName":"education/02-prompts/01-PRD","slug":"/education/prompts/PRD/hallucination-detection","permalink":"/vibe-labs/docs/education/prompts/PRD/hallucination-detection","draft":false,"unlisted":false,"editUrl":"https://github.com/EliFuzz/vibe-labs/docs/education/02-prompts/01-PRD/27-hallucination-detection.mdx","tags":[],"version":"current","sidebarPosition":27,"frontMatter":{"title":"Hallucination Detection","description":"Hallucination detection for the PRD","hide_table_of_contents":true},"sidebar":"education","previous":{"title":"Quality Assurance","permalink":"/vibe-labs/docs/education/prompts/PRD/quality-assurance"},"next":{"title":"Summary","permalink":"/vibe-labs/docs/education/prompts/PRD/summary"}}');var a=i(3420),s=i(8906);const o={title:"Hallucination Detection",description:"Hallucination detection for the PRD",hide_table_of_contents:!0},r=void 0,c={},l=[];function u(e){const n={code:"code",pre:"pre",...(0,s.R)(),...e.components};return(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-markdown",children:'# Hallucination Detection and Fact-Checking Framework\n\n## Purpose\n\nProvide comprehensive framework for detecting and preventing hallucinated information in PRD development. This guide ensures all information is accurate, verifiable, and properly sourced.\n\n## Understanding AI Hallucination in PRD Context\n\n### What is Hallucination?\n\nAI hallucination occurs when AI systems generate information that appears plausible but is actually false, unsupported, or fabricated. In PRD context, this can include:\n\n- Invented market statistics or research data\n- Fabricated competitive information\n- Unrealistic technical specifications\n- Made-up user research insights\n- False regulatory or compliance claims\n\n### Why Hallucination is Dangerous in PRDs\n\n- **Business Risk**: Decisions based on false information can lead to failed products\n- **Resource Waste**: Incorrect estimates lead to budget and timeline overruns\n- **Credibility Loss**: Inaccurate PRDs damage professional credibility\n- **Legal Risk**: False compliance claims can create legal liability\n- **Strategic Misalignment**: Wrong market data leads to poor strategic decisions\n\n## Hallucination Detection Framework\n\n### 1. Information Source Verification\n\n**Red Flags for Fabricated Sources:**\n\n- Overly specific statistics without clear sources\n- Round numbers that seem too convenient (exactly 50%, 75%, etc.)\n- Market research from unknown or unverifiable sources\n- Competitive data that seems too detailed or insider-like\n- Technical specifications that seem too good to be true\n\n**Verification Process:**\n\n## Source Verification Checklist\n\n### For Market Data:\n\n- [ ] Source is a recognized research firm (Gartner, IDC, Forrester, etc.)\n- [ ] Publication date is recent (within 2 years for market data)\n- [ ] Methodology is described or available\n- [ ] Data is consistent with other credible sources\n- [ ] Sample size and scope are appropriate\n\n### For Competitive Information:\n\n- [ ] Information is from public sources (websites, press releases, etc.)\n- [ ] Claims are verifiable through multiple sources\n- [ ] Information is current and not outdated\n- [ ] No insider or confidential information is claimed\n- [ ] Competitive analysis is objective, not biased\n\n### For Technical Information:\n\n- [ ] Technical specifications are realistic and achievable\n- [ ] Performance claims are backed by benchmarks or tests\n- [ ] Technology choices are appropriate for use case\n- [ ] Integration capabilities are verified with vendors\n- [ ] Security claims are validated against standards\n\n### For User Research:\n\n- [ ] Research methodology is clearly described\n- [ ] Sample sizes are adequate for conclusions drawn\n- [ ] Research is recent and relevant to target users\n- [ ] Findings are consistent with known user behavior\n- [ ] Quotes and insights feel authentic, not fabricated\n\n### 2. Plausibility Assessment\n\n**Market Data Plausibility:**\n\n- Market size claims should be reasonable relative to related markets\n- Growth rates should align with industry trends\n- Market penetration assumptions should be conservative\n- Revenue projections should be based on realistic adoption curves\n\n**Technical Plausibility:**\n\n- Performance specifications should align with current technology capabilities\n- Development timelines should account for complexity and unknowns\n- Integration requirements should be technically feasible\n- Scalability claims should be supported by architecture analysis\n\n**User Behavior Plausibility:**\n\n- User adoption rates should align with similar products\n- User engagement patterns should be realistic\n- User satisfaction targets should be achievable\n- User workflow assumptions should match real-world behavior\n\n### 3. Consistency Checking\n\n**Cross-Section Consistency:**\n\n## Consistency Validation Framework\n\n### Market and User Consistency:\n\n- [ ] Target market size aligns with user persona populations\n- [ ] Market trends support user needs and behaviors\n- [ ] Competitive landscape matches user alternatives\n- [ ] Market opportunity justifies user acquisition costs\n\n### Technical and Functional Consistency:\n\n- [ ] Technical architecture supports all functional requirements\n- [ ] Performance requirements are achievable with proposed architecture\n- [ ] Integration requirements are technically feasible\n- [ ] Security requirements align with technical capabilities\n\n### Business and Financial Consistency:\n\n- [ ] Revenue projections align with user adoption estimates\n- [ ] Cost estimates align with technical and team requirements\n- [ ] Timeline estimates align with scope and complexity\n- [ ] Resource requirements support timeline and scope\n\n### User and Product Consistency:\n\n- [ ] Product features address identified user needs\n- [ ] User experience requirements align with user capabilities\n- [ ] Success metrics reflect real user value\n- [ ] User journey maps match product functionality\n\n## Fact-Checking Protocols\n\n### 1. Market Information Validation\n\n**Required Verification:**\n\n- **Market Size**: Verify through multiple credible sources\n- **Growth Rates**: Cross-check with industry reports\n- **Competitive Data**: Validate through public information\n- **Regulatory Information**: Confirm with legal/compliance experts\n\n**Validation Template:**\n\n## Market Fact Check: [Claim]\n\n### Original Claim:\n\n[Exact claim being verified]\n\n### Source Verification:\n\n**Primary Source**: [Original source of information]\n**Source Credibility**: [Assessment of source reliability]\n**Publication Date**: [When information was published]\n**Methodology**: [How data was collected]\n\n### Cross-Verification:\n\n**Source 2**: [Second source confirming information]\n**Source 3**: [Third source confirming information]\n**Discrepancies**: [Any differences between sources]\n\n### Plausibility Assessment:\n\n[Whether claim seems reasonable given context]\n\n### Verification Status:\n\n- [ ] Verified through multiple credible sources\n- [ ] Partially verified (some sources confirm)\n- [ ] Unverified (cannot find supporting sources)\n- [ ] Contradicted (sources disagree with claim)\n\n### Action Required:\n\n[What needs to be done based on verification results]\n\n### 2. Technical Information Validation\n\n**Technical Validation Process:**\n\n1. **Expert Review**: Have technical experts review all technical claims\n2. **Proof of Concept**: Validate critical technical assumptions through prototyping\n3. **Vendor Confirmation**: Confirm integration and third-party capabilities\n4. **Benchmark Research**: Validate performance claims against industry benchmarks\n\n### 3. User Research Validation\n\n**User Research Verification:**\n\n- **Methodology Review**: Ensure research methods are appropriate\n- **Sample Validation**: Confirm sample sizes and demographics\n- **Bias Assessment**: Check for research bias or leading questions\n- **Triangulation**: Validate findings through multiple research methods\n\n## Common Hallucination Patterns\n\n### 1. Market Data Hallucinations\n\n**Common Patterns:**\n\n- Overly precise market size figures (e.g., "$47.3 billion market")\n- Unrealistic growth rates (e.g., "300% annual growth")\n- Convenient round numbers (e.g., "exactly 50% of users want this feature")\n- Unattributed statistics (e.g., "studies show that...")\n\n**Detection Strategies:**\n\n- Require specific sources for all market data\n- Cross-check statistics with multiple sources\n- Verify that growth rates align with industry trends\n- Question statistics that seem too convenient or precise\n\n### 2. Competitive Intelligence Hallucinations\n\n**Common Patterns:**\n\n- Detailed competitive feature comparisons without public sources\n- Insider knowledge about competitor strategies\n- Unverified claims about competitor performance or metrics\n- Outdated competitive information presented as current\n\n**Detection Strategies:**\n\n- Limit competitive analysis to publicly available information\n- Verify all competitive claims through multiple sources\n- Date-stamp all competitive information\n- Acknowledge limitations in competitive intelligence\n\n### 3. Technical Specification Hallucinations\n\n**Common Patterns:**\n\n- Performance specifications that exceed industry standards\n- Integration capabilities that haven\'t been verified\n- Development timelines that ignore complexity\n- Security claims without proper validation\n\n**Detection Strategies:**\n\n- Have technical experts review all specifications\n- Validate performance claims through benchmarking\n- Confirm integration capabilities with vendors\n- Base timelines on similar project experience\n\n## Assumption Management Framework\n\n### 1. Assumption Identification\n\n**Types of Assumptions:**\n\n- **Market Assumptions**: About market size, growth, and behavior\n- **User Assumptions**: About user needs, behaviors, and adoption\n- **Technical Assumptions**: About feasibility, performance, and integration\n- **Business Assumptions**: About revenue, costs, and resources\n\n**Assumption Documentation:**\n\n## Assumption: [Clear statement of assumption]\n\n### Category: [Market/User/Technical/Business]\n\n### Confidence Level: [High/Medium/Low]\n\n### Impact if Wrong: [High/Medium/Low]\n\n### Evidence Supporting: [What evidence supports this assumption]\n\n### Evidence Against: [What evidence challenges this assumption]\n\n### Validation Method: [How assumption will be tested]\n\n### Validation Timeline: [When validation will occur]\n\n### Contingency Plan: [What to do if assumption is wrong]\n\n### Owner: [Who is responsible for validating this assumption]\n\n### 2. Assumption Validation Planning\n\n**Validation Methods:**\n\n- **User Research**: Surveys, interviews, usability testing\n- **Market Research**: Industry reports, competitive analysis\n- **Technical Validation**: Prototyping, proof of concepts, expert consultation\n- **Business Validation**: Financial modeling, stakeholder interviews\n\n### 3. Assumption Tracking and Updates\n\n**Tracking Framework:**\n\n- Regular assumption review meetings\n- Assumption validation status tracking\n- Updates to PRD based on validated/invalidated assumptions\n- Communication of assumption changes to stakeholders\n\n## Quality Assurance Checklist\n\n### Pre-Publication Validation:\n\n- [ ] All market data has credible sources\n- [ ] All competitive information is publicly verifiable\n- [ ] All technical specifications have been expert-reviewed\n- [ ] All user research has appropriate methodology\n- [ ] All financial projections have supporting models\n- [ ] All assumptions are clearly marked and documented\n- [ ] All claims are consistent across sections\n- [ ] All sources are current and relevant\n\n### Ongoing Validation:\n\n- [ ] Regular fact-checking reviews scheduled\n- [ ] Assumption validation plan in place\n- [ ] Stakeholder review process includes fact-checking\n- [ ] Updates to PRD reflect new validated information\n- [ ] Team trained on hallucination detection\n\n## Red Flag Indicators\n\n### Immediate Red Flags:\n\n- Statistics without sources\n- Overly precise or convenient numbers\n- Claims that seem too good to be true\n- Competitive intelligence that seems insider-like\n- Technical specifications that exceed industry norms\n- User research with unrealistic sample sizes or findings\n\n### Process Red Flags:\n\n- Pressure to include unverified information\n- Reluctance to document assumptions\n- Skipping fact-checking due to time pressure\n- Over-reliance on single sources\n- Dismissing contradictory evidence\n\n## Remediation Process\n\n### When Hallucination is Detected:\n\n1. **Stop and Assess**: Immediately stop using the questionable information\n2. **Investigate Scope**: Determine how much content may be affected\n3. **Find Accurate Information**: Research and verify correct information\n4. **Update Documentation**: Correct all affected sections\n5. **Review Process**: Understand how hallucination occurred\n6. **Prevent Recurrence**: Implement additional safeguards\n\n### Communication Protocol:\n\n- Notify stakeholders of any significant corrections\n- Explain impact of corrections on conclusions\n- Update version control with clear change documentation\n- Conduct lessons learned session to prevent future occurrences\n'})})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},8906:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var t=i(6672);const a={},s=t.createContext(a);function o(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);